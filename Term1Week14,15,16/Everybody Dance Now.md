# Everybody Dance Now

## 摘要

这篇论文提出了一种简单的方法来实现“按我做”的动作转移：给定一个舞蹈视频，我们可以将这个表演转移到一个新的（业余）目标对象身上，只需要几分钟时间让目标对象执行标准动作。我们将这个问题视为视频到视频的转换，使用姿势作为中间表示。为了转移动作，我们从源主体中提取姿势，并应用学到的姿势到外观的映射来生成目标主体。我们预测两个连续帧以实现时间上的一致性视频效果，并为逼真的面部合成引入了一个单独的处理流程。

尽管我们的方法相当简单，但却产生了令人惊讶的有说服力的结果（见视频）。这也激励我们提供一种取证工具，用于可靠的合成内容检测，能够区分我们系统合成的视频和真实数据。此外，我们发布了一个前所未有的开源视频数据集，这些视频可以合法用于训练和动作转移。