# 面向新领域的基础模型姿态估计适配（2024–2025）

**概述：**
 最新研究强调将**大规模预训练的姿态估计模型**（例如 Meta 的 **Sapiens** 或 ViTPose 系列）**微调到特定人群**（如婴儿、老年人等），且假设目标域数据充足。与少样本或无监督的方法不同，这类方法假设**目标域有足够的标注数据**，研究重点转向**架构改造、微调策略和领域特定泛化**。核心思路包括替换或扩展输出头、冻结或适配部分模型层、**有监督的领域适应**技术、处理**不同人体骨架拓扑**（例如全身 vs. 标准关节点、成人 vs. 婴儿比例差异），以及利用深度等附加模态。下面综述了 2024–2025 年 CVPR、ICCV、ECCV 上的代表性工作，涵盖模型架构、训练策略、创新点，以及它们对特定人群适配的参考意义。

------

## Sapiens（Meta，2024）：面向人类视觉任务的基础模型

**模型与架构：**
 **Sapiens**  是一系列**视觉Transformer（ViT）模型**（参数量最高达 20 亿），在 **Humans-300M** 数据集（包含 3 亿张野外人像）上进行预训练 。该模型的独特之处在于支持 **1024×1024 高分辨率输入** ，适配**1K分辨率推理**以进行高精度人体分析。预训练使用自监督的 Masked Autoencoder (MAE) 方法，仅在人体图像上训练，从而获得**强大的人类特征表示**。在下游任务中，Sapiens 采用**编码器–解码器结构**：ViT 编码器加载预训练权重，新加入的任务解码头从零开始训练 。**整个模型端到端微调** ，使其能快速适配到新任务。

**密集关键点表示：**
 为提升姿态估计精度，Sapiens 引入了**308个全身关键点**（包括 243 个面部和 40 个手部点），比标准的17或68个点集详细得多。通过多视角采集流程构建了高质量密集标注数据集 Humans-5K 。这种高密度标注提升了对人体形态的刻画能力 。

**微调策略：**
 Sapiens 展示了**领域特定预训练 + 有监督微调**的优势。首先在大规模多样化人体数据上进行预训练，然后在少量但高质量的标注数据上微调整个模型（包括编码器和解码头）  。这一策略充分利用了大模型容量，让其在新领域捕捉细微差异。

**性能与泛化：**
 在 Humans-5K（全身姿态）上，Sapiens 明显优于之前的 SOTA，例如 Sapiens-0.6B 比 DWPose-L 高出 **2.1 AP**（56.2 vs 53.1），Sapiens-2B 更是提升 **7 AP**（61.1 vs 53.1）。即使在模型规模相近的情况下，也优于 ViTPose+。此外，Sapiens 在人体部位分割、深度估计等任务上同样通过微调获得 SOTA  ，展示了其广泛适配性。

**适用性：**
 在特定人群适配方面，Sapiens 证明了**只要有足够高质量标注数据，大型人类预训练ViT的端到端微调就能得到最优性能**。例如，可以将 Sapiens 微调到婴儿或老年人姿态数据集上，并调整关键点定义以获得专用模型。其核心优势是预训练先验强大，使得模型能从中等规模的目标域数据中学习细致的领域特征  。

------

## ViTPose 与 ViTPose++（Xu 等，2022–2023）：可扩展的纯Transformer及多任务适配

**模型与架构：**
 **ViTPose** 提出了一个**非常简洁却高效的基线**：一个**纯ViT编码器**（非分层，标准ViT架构）与一个轻量解码器相结合，用于姿态估计。与早期在CNN骨干上叠加Transformer或设计专用注意力模块的方法不同，ViTPose 证明了一个在图像上预训练的普通ViT就能作为强大的特征提取器，同时适用于**top-down**和**bottom-up**两种2D姿态估计范式。解码器结构非常简洁（两层反卷积+一层卷积生成K个关键点的热图），依赖编码器的表征能力。作者将模型从约2000万参数扩展到10亿参数，展示了**ViT的可扩展性**：在规模提升时，性能持续提升且无需特别技巧。

**训练与微调：**
 ViTPose 采用**灵活的预训练与微调流程**。可选择从ImageNet分类预训练权重初始化，或使用MAE自监督在无标签姿态图像上预训练。作者发现，用姿态数据而非ImageNet进行MAE预训练，同样能为下游任务提供足够的初始化能力。这与 Sapiens 的发现一致——**领域特定预训练可提升下游表现**。
 在微调阶段，ViTPose 通常在目标姿态数据集（如COCO关键点）上**端到端训练整个模型**，采用有监督方式。其高度灵活性意味着，同一ViTPose模型可以在不同范式下（top-down或bottom-up）通过不同数据准备方式进行训练，而无需改动网络结构。这种Transformer编码器的任务无关性，使其可在人体与动物姿态任务之间迁移。

**性能表现：**
 ViTPose 在主流人体姿态基准（COCO、MPII等）上达到了**SOTA**，其最大模型（ViTPose-G，约10亿参数）在COCO test-dev上无需测试时增强即创下新纪录。更值得注意的是，相同的ViTPose架构在**全身姿态**（COCO-WholeBody）和**动物姿态**（AP-10K、APT-36K）任务上也表现出色——尽管这些任务的关键点定义差异很大。不过，原始ViTPose仍然是针对单任务训练的（如COCO和WholeBody分开训练）。

**ViTPose++——知识分解（Knowledge Factorization）：**
 为解决多域多骨架任务适配问题，后续的 **ViTPose++** 引入了**任务特定前馈网络（FFN）实现知识分解**的新架构改造。在具体实现上，ViTPose++在每个Transformer层中**共享任务无关的自注意力部分**，但为不同任务配置**任务特定的FFN参数**。这样，注意力层学习所有任务的共享表征，而FFN则针对每种关键点配置进行特化。在推理时，根据任务选择对应的FFN“专家”即可。此外，ViTPose++还引入了**知识token**用于蒸馏，让小模型能在无需复杂蒸馏流程的情况下学习大模型的知识。

**多任务结果：**
 借助这些改造，ViTPose++在**多种姿态估计任务上同时达到SOTA**。一个模型（带多套FFN/解码头）在COCO人体、COCO-WholeBody（133点）、AI Challenger、MPII，以及AP-10K和APT-36K动物姿态任务上均实现领先，而且**推理速度与单任务模型相同**。这说明只需在大型Transformer中增加少量任务特定模块，就能在有监督多任务场景下实现跨骨架泛化。

**适用性：**
 在将基础模型适配到新领域时，ViTPose++ 展示了**模块化架构**的价值。如果需要将ViTPose适配到新域（例如某医疗场景的专用关键点集），可以选择增加任务特定模块（如FFN分支）而不是完全重新训练。这种做法保留了通用姿态知识，同时允许针对新任务进行细化优化。知识token的思路还暗示了一种高效微调路径——仅通过学习一个小的token或适配器模块，就能向模型注入新领域知识，这与参数高效微调（如LoRA或Adapter）方向相契合。

此外，一项独立研究（Jahn 等，2025）在婴儿运动分析中发现：**未专门为婴儿训练的ViTPose通用模型，初始性能就优于专用婴儿模型**，而在婴儿数据上进行有监督微调后，精度进一步显著提升。这验证了**先用大模型泛化能力，再通过目标域数据微调**的有效性。同时，该研究提醒，过度在窄域上训练的模型可能在稍微不同的分布上表现不佳，因此微调数据集应尽量多样化（如不同视角和场景）。

------

## PoseBH（Jeong 等，2025）：基于原型表示的多数据集训练

**研究问题：**
 在将姿态估计模型适配到新领域时，往往会出现**灾难性遗忘**，导致原始领域性能下降，或者在不同关键点体系间出现不兼容问题。**PoseBH**（2025）针对这一问题，提出在**多个人体姿态数据集上同时训练**，以实现跨域泛化。
 核心挑战在于**骨架异构性**：不同数据集的关键点定义差异很大（如COCO是17点、MPII是16点、COCO-WholeBody是133点含面部/手部，动物数据集关键点更完全不同）。如果直接合并数据或用多个独立输出头，会遇到两个问题：

1. 关键点大多不重叠，或语义存在差异；
2. 每张图像只标注了所属数据集的关键点，其它关键点是“缺失标签”。
    这既是**标签异构问题**，也是**半监督学习问题**。

**架构——关键点原型（Prototype）：**
 PoseBH 引入了**统一的关键点嵌入空间和可学习的原型向量**。
 与其为每个数据集单独设置解码头，不如用一个共享的嵌入头，将骨干特征映射到任意关键点的嵌入表示。
 同时，模型维护一组**原型向量**，每个向量代表所有数据集的某个关键点类型。训练时，对于来自数据集A的图像，模型通过计算像素嵌入与原型的相似度，得到各关键点的热图，然后只对数据集A有标注的关键点计算监督损失，其他关键点保持无监督状态。
 这种机制强迫模型为语义相似的关节（如人类的“左眼”和动物的“左眼”）学习共同的表示，并在推理时可以直接输出任意数据集定义的关键点集合。

**跨类型自监督（Cross-Type Self-Supervision）：**
 为解决“缺失标签”问题，PoseBH 设计了**跨类型自监督机制**。
 对于数据集A的图像，模型仍然会预测其它数据集骨架的关键点位置（基于原型匹配）。虽然这些预测没有真值标注，但模型会对比不同预测路径（如直接预测 vs. 通过原型匹配预测）的结果，强制它们一致，从而对无标签关键点产生正则化效果。这一方法无需额外教师模型，也不依赖复杂增强，计算开销很小。

**训练与数据：**
 PoseBH 在五个数据集上联合训练：COCO、MPII、AI Challenger、COCO-WholeBody，以及两个动物数据集（AP-10K、APT-36K）。骨干网络是类似 ViTPose 的共享ViT。
 对比基线（如多解码头模型）发现，简单微调往往会遗忘原域性能，而PoseBH在保持原域性能的同时，显著提升了低资源域（如WholeBody和动物）的准确率。

**结果：**
 PoseBH 在 COCO-WholeBody、APT-36K 等代表性跨域任务上大幅超越之前的多数据集方法，同时**没有牺牲COCO或MPII精度**。此外，实验表明，PoseBH 学到的关键点嵌入在其它任务（如3D人体形状估计、3D手部重建）上也能迁移，说明其捕捉了可跨模态迁移的语义关键点特征。

**适用性：**
 如果希望将成人姿态模型适配到婴儿域，同时保留成人域性能（或反之），PoseBH 提供了一种方案——直接把婴儿数据作为一个新“域”加入联合训练，并为新关键点初始化原型向量进行学习。
 这种方法尤其适合**不同骨架定义的多域适配**，且不需要对所有数据集进行统一标注，训练时即可同时适配成人、婴儿、动物等多种姿态定义。

------

## DWPose（Yang 等，ICCV 2023）：两阶段蒸馏的全身姿态估计

**领域背景：**
 **DWPose**（*Distilled Whole-body Pose*）聚焦于从标准人体姿态（仅身体关节）向**全身姿态估计**适配，即同时定位**身体、面部、手部、脚部关键点**（如 COCO-WholeBody 的 133 个关键点）。
 全身姿态面临的挑战包括：**多尺度特征需求**（手指等关节尺寸极小，而躯干很大）、关键点数量增多，以及面部/手部在全身图像中数据相对稀缺。DWPose 并没有设计新架构，而是提出了一种**两阶段知识蒸馏（KD）训练策略**，将大模型的知识迁移到小模型，同时提升全身任务性能。

**架构：**
 基础模型为 **RTMPose**（MMPose 项目，2023），是一种在 COCO-WholeBody 上表现优异的 CNN 架构。DWPose 使用 RTMPose-x（超大）作为教师模型，RTMPose-l（大）作为学生模型，进行两阶段蒸馏：

- **阶段 1 – 全模型蒸馏 + 可见性感知监督：**
   学生从零开始训练，利用教师的**中间特征图**与最终**热图输出**作为监督信号。与常规做法不同，DWPose 在损失计算中**不忽略“不可见”关键点**：即使标注中某关键点被标记为遮挡，学生仍然使用教师的预测作为软标签进行学习。这为被遮挡关节提供了额外监督信号。训练中蒸馏损失权重逐步衰减，让学生在后期更多依赖自身预测。
- **阶段 2 – 冻结骨干的关键点头自蒸馏：**
   完成阶段 1 后，学生骨干网络已具备较强特征提取能力。在阶段 2 中，骨干被冻结，仅微调关键点解码头。具体方法是将学生模型克隆一份作为固定“教师”，另一份作为可训练“学生”，通过蒸馏损失约束两者输出一致。这一阶段仅占总训练时间约 20%，但能进一步提升精度。

**数据增强：**
 为弥补面部/手部细节数据不足，DWPose 引入 **UBody 数据集**，包含丰富的上半身图像与细致的手部、面部标注，通过数据混合提升了对细粒度关键点的鲁棒性。

**结果：**
 DWPose 在 COCO-WholeBody 上取得 SOTA，小型学生模型的全身 AP 为 **66.5**，超过了教师模型（65.3），比未蒸馏学生提升了 **+1.7 AP**。更小尺寸的模型也能通过该方法保持较高精度，方便部署。代码已开源到 MMPose 项目。

**微调启示：**
 DWPose 展示了**分阶段微调与蒸馏**在域适配中的潜力。对于大规模基础模型，可先在目标域（如婴儿全身姿态）用完整架构微调，再将其知识压缩到更高效的模型，以便部署到移动设备或实时系统。
 此外，阶段 2 的“冻结骨干，仅微调头”策略是一种**高效的部分微调方法**，既保留了通用特征，又快速适配了域特定细节，这与参数高效微调（如LoRA、Adapter）理念相通。

------

## 适配特殊人群的补充说明

上述方法虽主要面向通用人体姿态任务，但其技术手段可直接应用于婴儿、患者、老年人等特殊人群：

1. **当目标域标注数据充足（有监督适配）：**
    直接用目标域数据对大模型（如 ViTPose、Sapiens）进行端到端微调往往最有效。关键在于保证目标域的关键点定义与模型输出匹配；若不一致，可通过多数据集方法（如 PoseBH）或新建解码头适配。
2. **架构调整以适应身体差异：**
    婴儿的身体比例（大头短肢）和老年人的姿态分布（关节活动范围小）都与成年人不同。可在微调中引入领域先验（如 SHIFT 框架为婴儿设计的姿态先验）来增强物理合理性。
3. **利用深度/3D信息：**
    在具备深度摄像头或多视角拍摄条件下，可扩展模型输入通道或进行多任务训练（同时预测2D姿态与深度），以缓解遮挡问题并提高稳定性。
4. **泛化与评估：**
    微调数据应尽量涵盖多样化场景（不同角度、光照、环境），并在相似但独立的数据集上验证泛化性能，避免过拟合于单一拍摄条件。

